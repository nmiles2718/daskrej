{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leveraging dask to perform chunk-wise operations across stacks of images\n",
    "\n",
    "The goal of this notebook is produce a MWE of a chunk-wise median across a stack of data. The idea here is to reshape an array of 2D arrays into a single 3D array stack that has been chunked along the dimension we will compute across. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # sshhhhh\n",
    "\n",
    "import dask.array as da\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1) Create a toy array to work with\n",
    "Let's make a data-cube with the following dimensions (9, 3, 3). We will do this starting with a list of 81 integers from 1 to 81 that is reshaped to a (9, 3, 3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(dask_ans, numpy_ans):\n",
    "    try:\n",
    "        assert np.sum(dask_ans - numpy_ans) == 0\n",
    "    except AssertionError as e:\n",
    "        print('FAIL')\n",
    "    else:\n",
    "        print('PASS')\n",
    "\n",
    "def duration(st, et, convert=True):\n",
    "    deltat = et - st\n",
    "    units = 'minutes'\n",
    "    conversion = 1/60\n",
    "    deltat *= conversion\n",
    "    print(f\"Time to compute median: {deltat:.2f} {units}\")\n",
    "    return deltat, units\n",
    "        \n",
    "def da_median(da_array):\n",
    "    st = time.time()\n",
    "    da_med = da.map_blocks(np.median, da_array, axis=0, drop_axis=0).compute()\n",
    "    et = time.time()\n",
    "    runtime = duration(st, et)\n",
    "    return da_med, runtime\n",
    "\n",
    "def np_median(np_array):\n",
    "    st = time.time()\n",
    "    np_med = np.median(np_array, axis=0)\n",
    "    et = time.time()\n",
    "    runtime = duration(st, et)\n",
    "    return np_med, runtime\n",
    "\n",
    "def npstats(np_array):\n",
    "    nbytes = np_array.nbytes\n",
    "    units='kB'\n",
    "    conversion = 1e3\n",
    "    if nbytes > 1e6 and nbytes<1e9:\n",
    "        units='MB'\n",
    "        conversion = 1e6\n",
    "    \n",
    "    elif nbytes > 1e9:\n",
    "        units = 'GB'\n",
    "        conversion = 1e9\n",
    "        \n",
    "    array_mem_size = nbytes/conversion\n",
    "    print(f\"Size of numpy array {array_mem_size:.2f} {units}\")\n",
    "    return array_mem_size\n",
    "    \n",
    "    \n",
    "def make_array(use_dask=True, shape=(9, 3, 3), chunksize=(9, 1, 1)):\n",
    "    nsamp=1\n",
    "    for val in shape:\n",
    "        nsamp *= val \n",
    "\n",
    "    a = np.linspace(1,nsamp, nsamp)\n",
    "    final = a.reshape(shape)\n",
    "        \n",
    "    if use_dask:\n",
    "        final = da.from_array(final).rechunk(chunksize)\n",
    "        \n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the helper function <code>make_array</code> to generate <code>numpy</code> and <code>dask</code> arrays with the default size and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = make_array(use_dask=False)\n",
    "da_array = make_array(use_dask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>dask</code> arrays operate lazily, whereas <code>numpy</code> arrays are always in memory. Each time an operation is applied to a <code>dask</code> array, the task is delayed until it is explicity called.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = da_array[:, 1, 0]\n",
    "b = np_array[:, 2, 2]\n",
    "c = da_array[:, 2, 2].compute()\n",
    "d = da_array[:, 0, 0]\n",
    "e = da_array[:, 0, :2]\n",
    "print(a, '\\n', b, '\\n', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>dask</code> also provides two very handy visualization. The first is an HTML representation of the array object you have created, complete with _very_ useful metadata. The second is a static image of the object's task graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_array[0].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npstats(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the <code>map_blocks</code> function to apply any function we desire across the array chunks. Here we use <code>np.median</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_med = da.map_blocks(np.median, da_array, axis=0, drop_axis=0)\n",
    "print(da_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_med.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_med.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code>dask</code> results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "_ = da_med.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code>numpy</code> results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "_ = np.median(np_array, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here if your dataset is very small, <code>dask</code> performs much worse because of the overhead. When we increase the array sizes to mimic something like 5 full-frame ACS images, we see that chunked method with <code>dask</code> scales much better than <code>numpy</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_example = make_array(use_dask=False, shape=(5, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_example1 = make_array(\n",
    "    use_dask=True, \n",
    "    shape=(5, 1024, 1024),\n",
    "    chunksize=(5, 70, 300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_example = make_array(\n",
    "    use_dask=True, \n",
    "    shape=(5, 1024, 1024),\n",
    "    chunksize=(5, 70, 300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= (da_example1[0] - da_example[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.visualize(optimize_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.compute(optimize_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npstats(np_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ResourceProfiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ResourceProfiler(dt=0.5) as rprof:\n",
    "    np_med, np_time = np_median(np_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rprof.visualize(filename='np_array.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ResourceProfiler(dt=0.5) as da_rprof:\n",
    "    da_med, da_time = da_median(da_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_rprof.visualize(filename='da_array.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_numpy_test(narrays):\n",
    "    datadict = {'narrays':[],'runtime':[], }\n",
    "    for i in range(nsamples):\n",
    "        _test_array = \n",
    "        med, runtime = np_median(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = da_example.rechunk('auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing with the reductions module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median, example_chunked, axis=0, chunks=(1,1), drop_axis=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def da_median(a, axis=None, drop_axis=None, keepdims=None, dtype=None, split_every=None, out=None):\n",
    "    return da.map_blocks(np.median, a, axis=axis, drop_axis=drop_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@wraps(da_median)\n",
    "def median(\n",
    "        a,\n",
    "        axis=None,\n",
    "        dtype=None,\n",
    "        keepdims=False,\n",
    "        split_every=None,\n",
    "        out=None\n",
    "):\n",
    "    if dtype is not None:\n",
    "        dt = dtype\n",
    "\n",
    "    else:\n",
    "        dt = getattr(np.empty((1,), dtype=a.dtype).sum(), \"dtype\", object)\n",
    "\n",
    "    result = da.reduction(\n",
    "        a,\n",
    "        da_median,\n",
    "        da_median,\n",
    "        axis=axis,\n",
    "        keepdims=keepdims,\n",
    "        dtype=dt,\n",
    "        split_every=split_every,\n",
    "        out=out,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_chunked"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
